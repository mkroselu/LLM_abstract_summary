{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "016cfd1b-3877-4e4b-9e2d-07a85db35b83",
   "metadata": {},
   "source": [
    "# Step-by-Step Guide to Curate Data and Fine-Tune a Model Without Using NeMo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fa5f4b-5b9f-4722-aff5-d7a3e1fe7af6",
   "metadata": {},
   "source": [
    "## Step 1: Collect and Curate Data \n",
    "You can manually collect data from various sources such as scientific journals, research papers, and news articles, and organize it into a CSV file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf81061-9df2-419a-9606-4dc89908fc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example data\n",
    "data = {\n",
    "    'title': [\n",
    "        'AI in Remote Sensing: Current Trends',\n",
    "        'Multi-Sensor Data Integration for Enhanced Geospatial Analysis',\n",
    "        'Satellite Imagery for Environmental Monitoring',\n",
    "        'Advances in Hyperspectral Imaging for Agriculture'\n",
    "    ],\n",
    "    'abstract': [\n",
    "        'This paper explores the use of artificial intelligence in remote sensing and its current trends.',\n",
    "        'The integration of data from multiple sensors can provide better insights for geospatial analysis.',\n",
    "        'Satellite imagery is increasingly used for environmental monitoring and management.',\n",
    "        'Hyperspectral imaging advancements are improving agricultural monitoring and yield prediction.'\n",
    "    ],\n",
    "    'keywords': [\n",
    "        'AI, remote sensing, trends',\n",
    "        'multi-sensor, data integration, geospatial analysis',\n",
    "        'satellite imagery, environmental monitoring',\n",
    "        'hyperspectral imaging, agriculture, monitoring'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('remote_sensing_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f311a98b-be90-4d7e-bc68-ed0eb7039ef5",
   "metadata": {},
   "source": [
    "## Step 2: Fine-Tune the Model with HuggingFace\n",
    "Use the HuggingFace transformers library to fine-tune a language model on the curated dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "e8a2e153-8366-441f-b04f-6bb5da0d0796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'abstract'],\n",
       "        num_rows: 251\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['title', 'abstract'],\n",
       "        num_rows: 31\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['title', 'abstract'],\n",
       "        num_rows: 32\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments, AutoTokenizer, AutoConfig \n",
    "import torch\n",
    "from datasets import load_dataset \n",
    "\n",
    "dataset = load_dataset(\"csv\", data_files={\"train\": \"full_abstract_train.csv\", \"validation\": \"full_abstract_val.csv\", \"test\": \"full_abstract_test.csv\"})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "2891b16f-da02-42c6-82eb-b4a4a0f84ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50258, 768)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model and tokenizer\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# Add padding token if not present\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "# Resize model embeddings to accommodate the new padding token\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "e36d2bcd-bb6a-40e8-83ee-0b04ea5475c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc2c78a232bf4e5fb9b05cc4dbccc4d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/251 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d030b6e885ad487287ab9c4d9adc5073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/31 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04a3d7aa2acf42bdbb7cf03a921de47f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/32 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"abstract\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "# Tokenize dataset\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "b9be14f9-dfc1-4d85-b84a-aaf01e30eb23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A review of remote sensing for environmental monitoring in China'"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['title'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "5dd05a70-cbbc-4465-8dfc-79dee6db322a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example token IDs: [464, 3288, 2858, 318, 6393, 329, 1692, 9441, 290, 2478, 1201, 340, 3769, 1660, 4133, 11, 1956, 4133, 11, 10685, 4133, 290, 4258, 4133, 3503, 13, 1081, 257, 5922, 1499, 11, 2807, 468, 13923, 257, 2383, 1487, 287, 262, 3288, 2858, 287, 2274, 4647, 26, 290, 4361, 11, 9904, 290, 45116, 262, 3722, 286, 262, 2858, 318, 286, 1049, 12085, 13, 14444, 284, 262, 9695, 286, 1588, 12, 9888, 290, 8925, 13432, 11, 6569, 34244, 3037, 468, 587, 281, 35669, 3164, 329, 6142, 9904, 13, 770, 3348, 8088, 262, 11210, 4133, 11, 6712, 290, 4788, 329, 6142, 9904, 287, 2807, 11, 290, 262, 14901, 287, 2267, 290, 3586, 286, 6569, 34244, 422, 1936, 7612, 25, 25047, 6376, 45069, 11, 6142, 9904, 287, 6861, 3006, 11, 10016, 3006, 11, 7876, 3006, 290, 9691, 3006, 13, 383, 6569, 34244, 4981, 290, 5050, 329, 2972, 3858, 286, 6142, 9904, 11, 290, 262, 2176, 5479, 287, 2807, 389, 8569, 2280, 31880, 13, 770, 3348, 635, 2173, 503, 1688, 6459, 4683, 379, 262, 1459, 3800, 25, 11210, 12694, 2761, 11, 11521, 779, 6459, 286, 40522, 11, 13479, 287, 262, 45069, 1429, 286, 25047, 9633, 11, 20796, 1245, 2761, 11, 257, 1877, 4922, 286, 22771, 11, 262, 4939, 2694, 286, 41164, 290, 9815, 3781, 11, 290, 257, 3092, 286, 31350, 1176, 329, 4858, 40522, 13, 9461, 11, 262, 2478, 5182, 290, 2003, 11678, 389, 1234, 2651, 284, 1277, 262, 2267, 290, 3586, 286, 6142, 9904, 290, 4800, 287, 262, 649, 6980, 13, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257]\n"
     ]
    }
   ],
   "source": [
    "example_ids = tokenized_datasets['train'][0]['input_ids']\n",
    "print(f\"Example token IDs: {example_ids}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "0b427917-c6f7-4ccb-9915-bdc1592fa51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model vocab size: 50258\n",
      "Tokenizer vocab size: 50258\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model vocab size: {model.config.vocab_size}\")\n",
    "print(f\"Tokenizer vocab size: {len(tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "995e1160-abed-45b8-b037-5a4a9af11ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MEI-KUEI LU\\anaconda3\\envs\\test\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "CONTEXT_LENGTH = 512 \n",
    "config = AutoConfig.from_pretrained( \n",
    "    \"gpt2\",\n",
    "    vocab_size = len(tokenizer), \n",
    "    n_ctx = CONTEXT_LENGTH, \n",
    "    bos_token_id = tokenizer.bos_token_id, \n",
    "    eos_token_id = tokenizer.eos_token_id\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "63ecc4ac-106e-4a55-b4b8-bd25b2ce901d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 size:124.4M parameters\n"
     ]
    }
   ],
   "source": [
    "model = GPT2LMHeadModel(config)\n",
    "model_size = sum(t.numel() for t in model.parameters()) \n",
    "print(f\"GPT-2 size:{model_size/1000**2:.1f}M parameters\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "dce323e9-a58a-457b-b19d-8b1c960361b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Config {\n",
       "  \"_name_or_path\": \"gpt2\",\n",
       "  \"activation_function\": \"gelu_new\",\n",
       "  \"architectures\": [\n",
       "    \"GPT2LMHeadModel\"\n",
       "  ],\n",
       "  \"attn_pdrop\": 0.1,\n",
       "  \"bos_token_id\": 50256,\n",
       "  \"embd_pdrop\": 0.1,\n",
       "  \"eos_token_id\": 50256,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"model_type\": \"gpt2\",\n",
       "  \"n_ctx\": 512,\n",
       "  \"n_embd\": 768,\n",
       "  \"n_head\": 12,\n",
       "  \"n_inner\": null,\n",
       "  \"n_layer\": 12,\n",
       "  \"n_positions\": 1024,\n",
       "  \"reorder_and_upcast_attn\": false,\n",
       "  \"resid_pdrop\": 0.1,\n",
       "  \"scale_attn_by_inverse_layer_idx\": false,\n",
       "  \"scale_attn_weights\": true,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.1,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"task_specific_params\": {\n",
       "    \"text-generation\": {\n",
       "      \"do_sample\": true,\n",
       "      \"max_length\": 50\n",
       "    }\n",
       "  },\n",
       "  \"transformers_version\": \"4.41.2\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50258\n",
       "}"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config # what we use to create a model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "a1aaaf64-9363-4ffb-add9-ae6c81fc46aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409bf9a2-0533-4309-a739-d31a6c4130bd",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "f59689f3-6833-41f6-b551-4b4b41fb79f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MEI-KUEI LU\\anaconda3\\envs\\test\\lib\\site-packages\\transformers\\training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    auto_find_batch_size = True, \n",
    "    num_train_epochs = 2,\n",
    "    gradient_accumulation_steps = 8, \n",
    "    weight_decay = 0.1,\n",
    "    lr_scheduler_type = \"cosine\", \n",
    "    learning_rate=5e-4, # 2e-5\n",
    "    fp16 = True, \n",
    "    logging_steps = 10 \n",
    "    # per_device_train_batch_size=16,\n",
    "\n",
    "\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "cb0ba6b6-c763-4c74-800e-d4204d98f1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"], \n",
    "    data_collator = data_collator, \n",
    "    tokenizer = tokenizer \n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "41dc8461-8ab8-4776-aaf9-ded043405b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 35:23, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>9.320814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>6.519324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8, training_loss=9.724644660949707, metrics={'train_runtime': 2458.6672, 'train_samples_per_second': 0.204, 'train_steps_per_second': 0.003, 'total_flos': 131168600064000.0, 'train_loss': 9.724644660949707, 'epoch': 2.0})"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "94acc1d6-db40-4266-b1ac-a243b8fcedb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fine_tuned_model_full_abstract\\\\tokenizer_config.json',\n",
       " 'fine_tuned_model_full_abstract\\\\special_tokens_map.json',\n",
       " 'fine_tuned_model_full_abstract\\\\vocab.json',\n",
       " 'fine_tuned_model_full_abstract\\\\merges.txt',\n",
       " 'fine_tuned_model_full_abstract\\\\added_tokens.json')"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"fine_tuned_model_full_abstract\")\n",
    "tokenizer.save_pretrained(\"fine_tuned_model_full_abstract\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1ba953-f45e-4a48-b557-2e90c0d6b1a7",
   "metadata": {},
   "source": [
    "## Using Our Model In Pipeline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "32d54f04-220c-4789-9d99-4d00b26daad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from transformers import pipeline \n",
    "\n",
    "pipe = pipeline( \n",
    "    \"text-generation\", model = \"fine_tuned_model_full_abstract\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "99686986-4c63-4189-a98a-9ac0d451dad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Assessment of land use land cover changes and future predictions using CA-ANN simulation for selangor, Malaysia',\n",
       " 'abstract': 'Land use land cover (LULC) has altered dramatically because of anthropogenic activities, particularly in places where climate change and population growth are severe. The geographic information system (GIS) and remote sensing are widely used techniques for monitoring LULC changes. This study aimed to assess the LULC changes and predict future trends in Selangor, Malaysia. The satellite images from 1991–2021 were classified to develop LULC maps using support vector machine (SVM) classification in ArcGIS. The image classification was based on six different LULC classes, i.e., (i) water, (ii) developed, (iii) barren, (iv) forest, (v) agriculture, and (vi) wetlands. The resulting LULC maps illustrated the area changes from 1991 to 2021 in different classes, where developed, barren, and water lands increased by 15.54%, 1.95%, and 0.53%, respectively. However, agricultural, forest, and wetlands decreased by 3.07%, 14.01%, and 0.94%, respectively. The cellular automata-artificial neural network (CA-ANN) technique was used to predict the LULC changes from 2031–2051. The percentage of correctness for the simulation was 82.43%, and overall kappa value was 0.72. The prediction maps from 2031–2051 illustrated decreasing trends in (i) agricultural by 3.73%, (ii) forest by 1.09%, (iii) barren by 0.21%, (iv) wetlands by 0.06%, and (v) water by 0.04% and increasing trends in (vi) developed by 5.12%. The outcomes of this study provide crucial knowledge that may help in developing future sustainable planning and management, as well as assist authorities in making informed decisions to improve environmental and ecological conditions.'}"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = dataset['test'][2]\n",
    "sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "b84135af-21c3-4083-b4da-384fcf1a25ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'ABSTRACT:Land use land cover (LULC) has altered dramatically because of anthropogenic activities, particularly in places where climate change and population growth are severe. The geographic information system (GIS) and remote sensing are widely used techniques for monitoring LULC changes. This study aimed to assess the LULC changes and predict future trends in Selangor, Malaysia. The satellite images from 1991–2021 were classified to develop LULC maps using support vector machine (SVM) classification in ArcGIS. The image classification was based on six different LULC classes, i.e., (i) water, (ii) developed, (iii) barren, (iv) forest, (v) agriculture, and (vi) wetlands. The resulting LULC maps illustrated the area changes from 1991 to 2021 in different classes, where developed, barren, and water lands increased by 15.54%, 1.95%, and 0.53%, respectively. However, agricultural, forest, and wetlands decreased by 3.07%, 14.01%, and 0.94%, respectively. The cellular automata-artificial neural network (CA-ANN) technique was used to predict the LULC changes from 2031–2051. The percentage of correctness for the simulation was 82.43%, and overall kappa value was 0.72. The prediction maps from 2031–2051 illustrated decreasing trends in (i) agricultural by 3.73%, (ii) forest by 1.09%, (iii) barren by 0.21%, (iv) wetlands by 0.06%, and (v) water by 0.04% and increasing trends in (vi) developed by 5.12%. The outcomes of this study provide crucial knowledge that may help in developing future sustainable planning and management, as well as assist authorities in making informed decisions to improve environmental and ecological conditions.\\n\\nTITLE: 16 terrestrial the (- neural the., the in\\nGROUND the data (GROUND, maps.ation'}]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = f\"ABSTRACT:{sample['abstract']}\\n\\nTITLE:\"\n",
    "pipe(prompt, max_new_tokens = 128) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "caf2630d-d16e-46fb-8bd4-7f7d5aa0a1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'ABSTRACT:Land use land cover (LULC) has altered dramatically because of anthropogenic activities, particularly in places where climate change and population growth are severe. The geographic information system (GIS) and remote sensing are widely used techniques for monitoring LULC changes. This study aimed to assess the LULC changes and predict future trends in Selangor, Malaysia. The satellite images from 1991–2021 were classified to develop LULC maps using support vector machine (SVM) classification in ArcGIS. The image classification was based on six different LULC classes, i.e., (i) water, (ii) developed, (iii) barren, (iv) forest, (v) agriculture, and (vi) wetlands. The resulting LULC maps illustrated the area changes from 1991 to 2021 in different classes, where developed, barren, and water lands increased by 15.54%, 1.95%, and 0.53%, respectively. However, agricultural, forest, and wetlands decreased by 3.07%, 14.01%, and 0.94%, respectively. The cellular automata-artificial neural network (CA-ANN) technique was used to predict the LULC changes from 2031–2051. The percentage of correctness for the simulation was 82.43%, and overall kappa value was 0.72. The prediction maps from 2031–2051 illustrated decreasing trends in (i) agricultural by 3.73%, (ii) forest by 1.09%, (iii) barren by 0.21%, (iv) wetlands by 0.06%, and (v) water by 0.04% and increasing trends in (vi) developed by 5.12%. The outcomes of this study provide crucial knowledge that may help in developing future sustainable planning and management, as well as assist authorities in making informed decisions to improve environmental and ecological conditions. ( aeros of. the, and. the, apology there identified. of thee and. data the interpretatione'}]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = f\"ABSTRACT:{sample['abstract']}\"\n",
    "pipe(prompt, max_new_tokens = 128) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
